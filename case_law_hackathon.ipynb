{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import json\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 200\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pprint\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition\n",
    "import gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illinois dataset\n",
    "path = r'C:\\Users\\ilyaa\\Desktop\\data\\data.jsonl.xz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list to hold the sampled cases \n",
    "cases = []\n",
    "max_cases = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cases: 10000\n"
     ]
    }
   ],
   "source": [
    "with lzma.open(path) as inline:\n",
    "    for i, line in enumerate(inline):\n",
    "        record = json.loads(str(line, 'utf-8'))\n",
    "        cases.append(record)\n",
    "        if i == max_cases - 1:\n",
    "            print(\"Number of Cases:\", len(cases))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML parsing function\n",
    "def ET_parse_xml(case):\n",
    "    feat_dict = {}\n",
    "    header = True\n",
    "    feat_dict[\"court\"] = case['court']['name']\n",
    "    feat_dict[\"date\"] = case['decision_date']\n",
    "    for elem in ET.fromstring(case['casebody']['data']):\n",
    "        opinions = []\n",
    "        if elem.tag.split(\"}\")[1] == \"opinion\":\n",
    "            op = {}\n",
    "            text = []\n",
    "            op[\"type\"] = elem.attrib[\"type\"]\n",
    "            op[\"author\"] = \"\"\n",
    "            for opinion_element in elem.getchildren():\n",
    "                if opinion_element.tag.split(\"}\")[1] == 'author':\n",
    "                    op[\"author\"] = opinion_element.text.replace(u'\\xad', '')\n",
    "                else:\n",
    "                    text.append(opinion_element.text.replace(u'\\xad', ''))\n",
    "            op[\"text\"] = \" \".join(text)\n",
    "            opinions.append(op)\n",
    "    feat_dict[\"opinions\"] = opinions\n",
    "    return feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each file, parse with parse_xml() and add to list of parsed files\n",
    "parsed_files = []\n",
    "for case in cases:\n",
    "    doc = ET_parse_xml(case) \n",
    "    parsed_files.append(doc)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide into 2 periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas dataframe to visualize our dataset\n",
    "raw_df = pd.DataFrame(parsed_files)\n",
    "\n",
    "# Parse dates\n",
    "raw_df[\"date\"] = pd.to_datetime(raw_df[\"date\"])\n",
    "\n",
    "# Strip out some sparse early data\n",
    "df = raw_df[raw_df[\"date\"] >= '1820-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>court</th>\n",
       "      <th>date</th>\n",
       "      <th>opinions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Illinois Appellate Court</td>\n",
       "      <td>2003-05-02</td>\n",
       "      <td>[{'type': 'majority', 'author': 'PRESIDING JUSTICE McDADE', 'text': 'delivered the opinion of the court: Michael Ratliff-El filed a complaint for mandamus relief (735 ILCS 5/14 — 101 et seq. (West...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Illinois Appellate Court</td>\n",
       "      <td>2003-05-01</td>\n",
       "      <td>[{'type': 'majority', 'author': 'JUSTICE MAAG', 'text': 'delivered the opinion of the court: The plaintiffs, Amanda and Brittany Adams, by their father and next friend, Tommy Adams, and Tommy Adam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illinois Appellate Court</td>\n",
       "      <td>2003-04-25</td>\n",
       "      <td>[{'type': 'majority', 'author': 'PRESIDING JUSTICE HOPKINS', 'text': 'delivered the opinion of the court: The petitioner, Alisha Bowlby, appeals the trial court’s judgment dissolving her marriage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Illinois Appellate Court</td>\n",
       "      <td>2003-04-08</td>\n",
       "      <td>[{'type': 'majority', 'author': 'JUSTICE MAAG', 'text': 'delivered the opinion of the court: C. Michael Witters and Diane Witters (plaintiffs), individually and derivatively on behalf of Midwest T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Illinois Appellate Court</td>\n",
       "      <td>2003-03-20</td>\n",
       "      <td>[{'type': 'majority', 'author': 'PRESIDING JUSTICE THEIS', 'text': 'delivered the opinion of the court: Defendant, Blockbuster, Inc. BACKGROUND On February 18, 1999, plaintiffs filed a class-actio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      court       date  \\\n",
       "0  Illinois Appellate Court 2003-05-02   \n",
       "1  Illinois Appellate Court 2003-05-01   \n",
       "2  Illinois Appellate Court 2003-04-25   \n",
       "3  Illinois Appellate Court 2003-04-08   \n",
       "4  Illinois Appellate Court 2003-03-20   \n",
       "\n",
       "                                                                                                                                                                                                  opinions  \n",
       "0  [{'type': 'majority', 'author': 'PRESIDING JUSTICE McDADE', 'text': 'delivered the opinion of the court: Michael Ratliff-El filed a complaint for mandamus relief (735 ILCS 5/14 — 101 et seq. (West...  \n",
       "1  [{'type': 'majority', 'author': 'JUSTICE MAAG', 'text': 'delivered the opinion of the court: The plaintiffs, Amanda and Brittany Adams, by their father and next friend, Tommy Adams, and Tommy Adam...  \n",
       "2  [{'type': 'majority', 'author': 'PRESIDING JUSTICE HOPKINS', 'text': 'delivered the opinion of the court: The petitioner, Alisha Bowlby, appeals the trial court’s judgment dissolving her marriage ...  \n",
       "3  [{'type': 'majority', 'author': 'JUSTICE MAAG', 'text': 'delivered the opinion of the court: C. Michael Witters and Diane Witters (plaintiffs), individually and derivatively on behalf of Midwest T...  \n",
       "4  [{'type': 'majority', 'author': 'PRESIDING JUSTICE THEIS', 'text': 'delivered the opinion of the court: Defendant, Blockbuster, Inc. BACKGROUND On February 18, 1999, plaintiffs filed a class-actio...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = df.opinions.tolist()\n",
    "custom_stop_words = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class TokenGenerator:\n",
    "    def __init__( self, documents, stopwords ):\n",
    "        self.documents = documents\n",
    "        self.stopwords = stopwords\n",
    "        self.tokenizer = re.compile(r\"\\S+\") \n",
    "\n",
    "    def __iter__( self ):\n",
    "        print(\"Word2Vec model ...\")\n",
    "        for doc in self.documents:\n",
    "            tokens = []\n",
    "            for tok in self.tokenizer.findall( doc ):\n",
    "                if tok in self.stopwords:\n",
    "                    tokens.append( \"<stopword>\" )\n",
    "                elif len(tok) >= 2: \n",
    "                    tokens.append( tok )\n",
    "            yield tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "docgen = TokenGenerator( raw_documents, custom_stop_words )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TokenGenerator object at 0x00000159E0475080>\n"
     ]
    }
   ],
   "source": [
    "print(docgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-a52d28a733c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  \u001b[0msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                  workers=4)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\cert\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[0mbatch_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mhs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_train_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cert\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You can't pass a generator as the sentences argument. Try an iterator.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m             self.train(\n\u001b[0;32m    337\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cert\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(self, sentences, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m         \"\"\"\n\u001b[0;32m    479\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[1;32m--> 480\u001b[1;33m             sentences, progress_per=progress_per, trim_rule=trim_rule)\n\u001b[0m\u001b[0;32m    481\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         report_values = self.vocabulary.prepare_vocab(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cert\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[1;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[0mchecked_string_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msentence_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-2c6ec68d87f3>\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtok\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"<stopword>\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(docgen, \n",
    "                 size=300, \n",
    "                 window=4, \n",
    "                 sg = 1,\n",
    "                 min_count=1, \n",
    "                 workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
